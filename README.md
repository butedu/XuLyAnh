# Há»‡ Thá»‘ng Nháº­n Diá»‡n Ná»¥ CÆ°á»i

Há»‡ thá»‘ng phÃ¡t hiá»‡n khuÃ´n máº·t vÃ  phÃ¢n loáº¡i ná»¥ cÆ°á»i trong áº£nh sá»­ dá»¥ng **YOLOv8-face** vÃ  **SmileNetV2 (CNN residual vá»›i SE attention)**. Há»— trá»£ xá»­ lÃ½ áº£nh tÄ©nh, video, vÃ  cung cáº¥p API web Ä‘á»ƒ demo trá»±c tuyáº¿n.

## ğŸš€ Quick Start (Training Má»›i)

**CÃ¡ch nhanh nháº¥t Ä‘á»ƒ train model:**

```bash
# 1. CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# 2. Chuáº©n bá»‹ dá»¯ liá»‡u (náº¿u chÆ°a cÃ³)
python -m src.data.prepare_genki --raw-dir data/raw/genki4k --output-dir data/processed/genki4k --create-splits

# 3. Train vá»›i má»™t dÃ²ng lá»‡nh
python train_model.py
```

**Táº¥t cáº£ hyperparameters Ä‘Æ°á»£c config trong `config/train_config.yaml`** - khÃ´ng cáº§n nháº­p thá»§ cÃ´ng ná»¯a!

---

## ğŸ“‹ Tá»•ng Quan Há»‡ Thá»‘ng

### Kiáº¿n TrÃºc
```
áº¢nh Ä‘áº§u vÃ o â†’ YOLOv8-face (phÃ¡t hiá»‡n máº·t) â†’ SmileNet (phÃ¢n loáº¡i cÆ°á»i/khÃ´ng) â†’ Thá»‘ng kÃª + ChÃº thÃ­ch
```

### ThÃ nh Pháº§n ChÃ­nh
- **YOLOv8-face**: PhÃ¡t hiá»‡n khuÃ´n máº·t nhanh, chÃ­nh xÃ¡c (Ultralytics)
- **SmileNet**: Máº¡ng CNN residual 7 stage vá»›i backbone sÃ¢u, dropout regularization
- **SmileCounter**: Pipeline tÃ­ch há»£p phÃ¡t hiá»‡n + phÃ¢n loáº¡i + váº½ chÃº thÃ­ch
- **FastAPI Backend**: RESTful API cho web demo vÃ  xá»­ lÃ½ video
- **CLI Tool**: Script `main.py` cho xá»­ lÃ½ áº£nh nhanh tá»« command line

### Dataset
- **GENKI-4K**: 4000 áº£nh khuÃ´n máº·t Ä‘Æ°á»£c gÃ¡n nhÃ£n cÆ°á»i/khÃ´ng cÆ°á»i (dataset chÃ­nh)
- **RAF-DB**: (TÃ¹y chá»n) Dataset cáº£m xÃºc má»Ÿ rá»™ng, cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ tÄƒng Ä‘a dáº¡ng dá»¯ liá»‡u

### Cáº¥u TrÃºc ThÆ° Má»¥c
```
XuLyAnh/
â”œâ”€â”€ main.py                      # CLI xá»­ lÃ½ áº£nh Ä‘Æ¡n
â”œâ”€â”€ video_demo.py                # CLI xá»­ lÃ½ video
â”œâ”€â”€ requirements.txt             # Dependencies Python
â”œâ”€â”€ models/                      # Trá»ng sá»‘ Ä‘Ã£ train
â”‚   â”œâ”€â”€ smile_cnn_best.pth      # SmileNet checkpoint tá»‘t nháº¥t
â”‚   â”œâ”€â”€ yolov8n-face.pt         # YOLOv8-face pretrained
â”‚   â”œâ”€â”€ checkpoint.pt           # Full checkpoint (optimizer, scheduler)
â”‚   â””â”€â”€ training_history.json   # Lá»‹ch sá»­ huáº¥n luyá»‡n
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/                 # áº¢nh GENKI-4K (raw)
â”‚   â””â”€â”€ processed/              # CSV annotations Ä‘Ã£ xá»­ lÃ½
â”‚       â””â”€â”€ genki4k/
â”‚           â”œâ”€â”€ train.csv
â”‚           â”œâ”€â”€ val.csv
â”‚           â””â”€â”€ test.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ classifier/             # SmileNet architecture
â”‚   â”œâ”€â”€ detection/              # YOLOv8 wrapper
â”‚   â”œâ”€â”€ pipeline/               # SmileCounter pipeline
â”‚   â”œâ”€â”€ training/               # Training loop, datasets
â”‚   â””â”€â”€ data/                   # Data preprocessing scripts
â””â”€â”€ webapp/
    â”œâ”€â”€ backend/                # FastAPI server
    â””â”€â”€ frontend/               # HTML/CSS/JS interface
```

---

## ğŸš€ CÃ i Äáº·t & Cháº¡y ChÆ°Æ¡ng TrÃ¬nh

### BÆ°á»›c 1: Clone Repository
```powershell
git clone <repository-url>
cd XuLyAnh
```

### BÆ°á»›c 2: Táº¡o MÃ´i TrÆ°á»ng áº¢o
```powershell
python -m venv .venv
.\.venv\Scripts\activate
```

### BÆ°á»›c 3: CÃ i Äáº·t Dependencies
```powershell
pip install -r requirements.txt
```

**LÆ°u Ã½ GPU**: Náº¿u dÃ¹ng GPU, Ä‘áº£m báº£o CUDA toolkit tÆ°Æ¡ng thÃ­ch vá»›i PyTorch 2.2.1:
```powershell
# Kiá»ƒm tra CUDA version
nvidia-smi

# CÃ i PyTorch vá»›i CUDA (náº¿u cáº§n)
pip install torch==2.2.1 torchvision==0.17.1 --index-url https://download.pytorch.org/whl/cu118
```

### BÆ°á»›c 4: Táº£i Model YOLOv8-face
Táº£i pretrained model `yolov8n-face.pt` vÃ  Ä‘áº·t vÃ o thÆ° má»¥c `models/`:
```powershell
# Táº¡o thÆ° má»¥c models náº¿u chÆ°a cÃ³
New-Item -ItemType Directory -Force -Path models

# Táº£i model (vÃ­ dá»¥ tá»« Ultralytics hoáº·c nguá»“n khÃ¡c)
# Äáº·t file yolov8n-face.pt vÃ o models/
```

### BÆ°á»›c 5: Chuáº©n Bá»‹ Dá»¯ Liá»‡u GENKI-4K

**5.1. Táº£i Dataset**
- Táº£i GENKI-4K tá»« nguá»“n chÃ­nh thá»©c
- Giáº£i nÃ©n vÃ o `data/raw/genki4k/`

**5.2. Xá»­ LÃ½ Annotations**
```powershell
python -m src.data.prepare_genki `
    --raw-dir data/raw/genki4k `
    --output-dir data/processed/genki4k `
    --create-splits
```

Lá»‡nh nÃ y sáº½ táº¡o:
- `data/processed/genki4k/train.csv` (80%)
- `data/processed/genki4k/val.csv` (10%)
- `data/processed/genki4k/test.csv` (10%)

**5.3. Gom áº¢nh**
Copy toÃ n bá»™ áº£nh GENKI-4K vÃ o `data/images/` Ä‘á»ƒ training script Ä‘á»c Ä‘Æ°á»£c.

### BÆ°á»›c 6: Huáº¥n Luyá»‡n MÃ´ HÃ¬nh (TÃ¹y Chá»n)

**Náº¿u Ä‘Ã£ cÃ³ checkpoint:** Bá» qua bÆ°á»›c nÃ y, dÃ¹ng `models/smile_cnn_best.pth` sáºµn cÃ³.

#### ğŸš€ CÃ¡ch 1: Sá»­ dá»¥ng Script Python (KHUYáº¾N NGHá»Š)

```bash
python train_model.py
```

Script nÃ y sáº½:
- Tá»± Ä‘á»™ng kiá»ƒm tra GPU cÃ³ sáºµn khÃ´ng
- Training vá»›i config tá»« `config/train_config.yaml`
- Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh Ä‘áº¹p máº¯t vá»›i emoji vÃ  mÃ u sáº¯c
- Dá»… dÃ ng thÃªm arguments náº¿u cáº§n

#### ğŸ”§ CÃ¡ch 2: Training vá»›i Custom Config

**Chá»‰nh sá»­a hyperparameters trong `config/train_config.yaml`:**
```yaml
training:
  epochs: 50           # TÄƒng lÃªn 100 náº¿u muá»‘n train lÃ¢u hÆ¡n
  batch_size: 64       # Giáº£m xuá»‘ng 32 náº¿u GPU háº¿t RAM
  learning_rate: 5.0e-4
  
model:
  name: "SmileNetV2"   # DÃ¹ng kiáº¿n trÃºc má»›i vá»›i residual + SE attention
  use_se_block: true   # Báº­t Squeeze-and-Excitation attention
```

Sau Ä‘Ã³ cháº¡y:
```powershell
python -m src.training.train --config config/train_config.yaml
```

#### ğŸ¯ CÃ¡ch 3: Override Parameters tá»« Command Line

```powershell
python -m src.training.train `
    --config config/train_config.yaml `
    --epochs 60 `
    --batch-size 32 `
    --learning-rate 1e-4
```

#### ğŸ”„ Resume tá»« Checkpoint

Náº¿u training bá»‹ giÃ¡n Ä‘oáº¡n, resume tá»« checkpoint:
```powershell
python -m src.training.train `
    --config config/train_config.yaml `
    --resume models/checkpoint.pt
```

#### ğŸ“Š TÃ­nh NÄƒng Training Má»›i

**1. Kiáº¿n TrÃºc MÃ´ HÃ¬nh Cáº£i Tiáº¿n:**
- **SmileNetV2**: Residual blocks + SE attention (chÃ­nh xÃ¡c hÆ¡n 3-5%)
- 6 residual blocks vá»›i skip connections
- Squeeze-and-Excitation attention cho má»—i block
- Dropout regularization thÃ´ng minh

**2. Data Augmentation Máº¡nh HÆ¡n:**
- Random rotation Â±10Â°
- Color jitter (brightness, contrast, saturation, hue)
- Random erasing (cutout) - 30% probability
- Gaussian blur - 20% probability

**3. Training Techniques Hiá»‡n Äáº¡i:**
- **Mixed Precision Training**: Nhanh hÆ¡n 2-3x trÃªn GPU NVIDIA (FP16)
- **Learning Rate Warmup**: 5 epochs Ä‘áº§u tÄƒng LR tá»« 0 â†’ base_lr
- **Cosine Annealing**: LR giáº£m dáº§n theo cosine schedule
- **Gradient Clipping**: max_norm = 1.0 Ä‘á»ƒ trÃ¡nh exploding gradients
- **Early Stopping**: Dá»«ng tá»± Ä‘á»™ng náº¿u khÃ´ng cáº£i thiá»‡n sau 15 epochs

**4. Optimizer Má»›i:**
- **AdamW** vá»›i weight decay = 1e-4 (tá»‘t hÆ¡n Adam gá»‘c)
- L2 regularization tÃ­ch há»£p

**5. Monitoring & Logging:**
- In metrics Ä‘áº¹p vá»›i emoji vÃ  mÃ u sáº¯c
- Tá»± Ä‘á»™ng hiá»ƒn thá»‹ thÃ´ng tin GPU
- LÆ°u checkpoint Ä‘á»‹nh ká»³ má»—i 5 epochs
- Test evaluation sau khi training xong

Káº¿t quáº£:
- `models/smile_cnn_best.pth`: Trá»ng sá»‘ tá»‘t nháº¥t (theo F1 score)
- `models/checkpoint.pt`: Full checkpoint (optimizer, scheduler, epoch)
- `models/checkpoint_epoch_N.pt`: Checkpoint Ä‘á»‹nh ká»³
- `models/training_history.json`: Metrics Ä‘áº§y Ä‘á»§ theo tá»«ng epoch

---

## ğŸ’» Sá»­ Dá»¥ng Há»‡ Thá»‘ng

### 1. Xá»­ LÃ½ áº¢nh ÄÆ¡n (CLI)
```powershell
python main.py path/to/image.jpg --output result.jpg
```

**TÃ¹y chá»n:**
- `--weights`: ÄÆ°á»ng dáº«n checkpoint khÃ¡c (máº·c Ä‘á»‹nh `models/smile_cnn_best.pth`)
- `--face-model`: ÄÆ°á»ng dáº«n YOLOv8 khÃ¡c (máº·c Ä‘á»‹nh `models/yolov8n-face.pt`)
- `--device`: `cpu` hoáº·c `cuda`

**Káº¿t quáº£:**
- In ra console: sá»‘ máº·t phÃ¡t hiá»‡n, sá»‘ ngÆ°á»i cÆ°á»i, xÃ¡c suáº¥t tá»«ng máº·t
- LÆ°u áº£nh chÃº thÃ­ch vá»›i:
  - Khung **xanh lÃ¡**: Ä‘ang cÆ°á»i
  - Khung **Ä‘á»**: khÃ´ng cÆ°á»i
  - Text hiá»ƒn thá»‹ xÃ¡c suáº¥t

### 2. Web Demo (FastAPI)
```bash
uvicorn webapp.backend.main:app --host 127.0.0.1 --port 8000
```

Má»Ÿ trÃ¬nh duyá»‡t: `http://127.0.0.1:8000`

**Chá»©c nÄƒng:**
- Upload áº£nh â†’ Xem káº¿t quáº£ trá»±c tiáº¿p
- Táº£i áº£nh chÃº thÃ­ch vá» mÃ¡y
- Thá»‘ng kÃª realtime sá»‘ ngÆ°á»i cÆ°á»i

### 3. Xá»­ LÃ½ Video (CLI)
```powershell
python video_demo.py path/to/video.mp4 --output output_video.mp4
```

Xá»­ lÃ½ tá»«ng frame, ghi video cÃ³ chÃº thÃ­ch khuÃ´n máº·t vÃ  thá»‘ng kÃª.

---

## ğŸ”§ Cáº¥u HÃ¬nh NÃ¢ng Cao

### Config File (KHUYáº¾N NGHá»Š)

Chá»‰nh sá»­a `config/train_config.yaml` Ä‘á»ƒ tÃ¹y chá»‰nh toÃ n bá»™ training pipeline:

**Thay Ä‘á»•i kiáº¿n trÃºc model:**
```yaml
model:
  name: "SmileNetV2"      # Hoáº·c "SmileNet" cho baseline
  dropout: 0.3             # TÄƒng lÃªn 0.4-0.5 náº¿u bá»‹ overfit
  use_se_block: true       # Báº­t/táº¯t SE attention
  use_deep_residual: true  # Residual blocks sÃ¢u hÆ¡n
```

**Äiá»u chá»‰nh data augmentation:**
```yaml
augmentation:
  random_rotation: 15      # TÄƒng Ä‘á»™ rotation
  random_erasing:
    probability: 0.5       # TÄƒng xÃ¡c suáº¥t cutout
    scale: [0.02, 0.2]     # VÃ¹ng xÃ³a lá»›n hÆ¡n
  gaussian_blur:
    probability: 0.3       # Blur nhiá»u hÆ¡n
```

**Thay Ä‘á»•i learning rate schedule:**
```yaml
training:
  scheduler:
    type: "cosine"         # "step", "cosine", "reduce_on_plateau"
    warmup_epochs: 5       # Sá»‘ epoch warmup
    min_lr: 1.0e-6         # LR tá»‘i thiá»ƒu
```

**Báº­t/táº¯t cÃ¡c tÃ­nh nÄƒng:**
```yaml
settings:
  use_amp: true            # Mixed precision (chá»‰ GPU)
  grad_clip:
    enabled: true
    max_norm: 1.0
  early_stopping:
    enabled: true
    patience: 15           # Dá»«ng sau N epochs khÃ´ng cáº£i thiá»‡n
    min_delta: 0.001       # NgÆ°á»¡ng cáº£i thiá»‡n tá»‘i thiá»ƒu
```

### TÃ¹y Chá»‰nh Trá»±c Tiáº¿p Code

#### Thay Ä‘á»•i SmileNet Architecture

Chá»‰nh `src/classifier/smile_model.py`:
```python
# ThÃªm residual blocks
self.layer1 = self._make_layer(32, 64, num_blocks=3, ...)  # TÄƒng tá»« 2 lÃªn 3

# Thay Ä‘á»•i dropout
self.classifier = nn.Sequential(
    nn.Dropout(0.4),  # TÄƒng dropout
    ...
)
```

#### ThÃªm Custom Augmentation

Chá»‰nh `src/training/train.py` â†’ `build_transforms()`:
```python
# ThÃªm vÃ o training transforms
train_transforms.append(transforms.RandomAffine(
    degrees=15,
    translate=(0.1, 0.1),
    scale=(0.9, 1.1)
))
```

---

## ğŸ“Š Hiá»‡u Suáº¥t MÃ´ HÃ¬nh

### Baseline Model (SmileNet)
**Training Results (GENKI-4K, 25 epochs):**
- Validation Accuracy: **88.25%**
- Validation F1 Score: **0.8878**
- Validation Precision: **91.63%**
- Validation Recall: **86.11%**

**Kiáº¿n trÃºc:**
- 4 conv layers vá»›i BatchNorm
- Global average pooling
- 2-layer classifier head
- Dropout regularization (0.3)

### Improved Model (SmileNetV2) ğŸ†•

**Dá»± kiáº¿n cáº£i thiá»‡n (vá»›i config má»›i):**
- Validation Accuracy: **90-92%** (â†‘ 2-4%)
- Validation F1 Score: **0.91-0.93** (â†‘ 0.02-0.04)
- Tá»‘c Ä‘á»™ training: **2-3x nhanh hÆ¡n** (nhá» mixed precision)

**Cáº£i tiáº¿n chÃ­nh:**
- âœ… 6 residual blocks vá»›i skip connections
- âœ… Squeeze-and-Excitation attention
- âœ… Advanced data augmentation (rotation, erasing, blur)
- âœ… Mixed precision training (FP16)
- âœ… Cosine annealing + warmup
- âœ… AdamW optimizer vá»›i weight decay
- âœ… Gradient clipping + early stopping

**Kiáº¿n trÃºc SmileNetV2:**
```
Input (64x64x3)
  â†“
Conv2d(3â†’32) + BN + ReLU
  â†“
[ResBlock(32â†’64) + SE] Ã— 2  â†’ Downsample
  â†“
[ResBlock(64â†’128) + SE] Ã— 2 â†’ Downsample
  â†“
[ResBlock(128â†’256) + SE] Ã— 2 â†’ Downsample
  â†“
AdaptiveAvgPool(1Ã—1)
  â†“
Linear(256â†’128) + Dropout(0.3)
  â†“
Linear(128â†’2)
```

**So sÃ¡nh:**
| Metric | SmileNet | SmileNetV2 (Dá»± kiáº¿n) |
|--------|----------|----------------------|
| Parameters | ~500K | ~750K |
| F1 Score | 0.8878 | 0.91-0.93 |
| Inference Speed | 5ms | 6ms |
| GPU Memory | 1.2GB | 1.5GB |
| Training Time (50 epochs) | 45min | 30min (vá»›i AMP) |

---

## ğŸ›  Troubleshooting

### Lá»—i "KhÃ´ng tÃ¬m tháº¥y config file"
- Äáº£m báº£o file `config/train_config.yaml` tá»“n táº¡i
- Hoáº·c chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n khÃ¡c: `--config path/to/config.yaml`

### Lá»—i "KhÃ´ng tÃ¬m tháº¥y checkpoint"
- Kiá»ƒm tra file `models/smile_cnn_best.pth` vÃ  `models/yolov8n-face.pt` tá»“n táº¡i
- Náº¿u chÆ°a train, pháº£i cháº¡y bÆ°á»›c huáº¥n luyá»‡n trÆ°á»›c
- Vá»›i SmileNetV2, cÃ³ thá»ƒ cáº§n train láº¡i tá»« Ä‘áº§u

### Lá»—i CUDA out of memory
**Giáº£i phÃ¡p:**
1. Giáº£m batch_size trong config:
   ```yaml
   training:
     batch_size: 32  # Hoáº·c 16
   ```
2. Táº¯t mixed precision:
   ```yaml
   settings:
     use_amp: false
   ```
3. Giáº£m sá»‘ workers:
   ```yaml
   settings:
     num_workers: 2
   ```
4. Hoáº·c train trÃªn CPU (cháº­m):
   ```yaml
   settings:
     device: "cpu"
   ```

### Accuracy tháº¥p / Model khÃ´ng há»c
**CÃ¡c cÃ¡ch kháº¯c phá»¥c:**

1. **TÄƒng epochs vÃ  giáº£m learning rate:**
   ```yaml
   training:
     epochs: 80
     learning_rate: 1.0e-4
   ```

2. **Giáº£m augmentation náº¿u quÃ¡ máº¡nh:**
   ```yaml
   augmentation:
     random_rotation: 5     # Giáº£m tá»« 10
     random_erasing:
       probability: 0.2     # Giáº£m tá»« 0.3
   ```

3. **Thá»­ optimizer khÃ¡c:**
   ```yaml
   training:
     optimizer:
       type: "sgd"          # Thay vÃ¬ adamw
       momentum: 0.9
   ```

4. **Kiá»ƒm tra data:**
   ```powershell
   python -c "import pandas as pd; df=pd.read_csv('data/processed/genki4k/train.csv'); print(df['label'].value_counts())"
   ```
   Äáº£m báº£o labels cÃ¢n báº±ng (50/50 hoáº·c gáº§n Ä‘Ã³)

5. **Resume tá»« baseline model:**
   - Train SmileNet (baseline) trÆ°á»›c
   - Sau Ä‘Ã³ chuyá»ƒn sang SmileNetV2

### Model overfit (train acc cao, val acc tháº¥p)
- TÄƒng dropout trong config: `dropout: 0.4`
- TÄƒng augmentation probability
- ThÃªm weight_decay: `weight_decay: 5.0e-4`
- Enable early stopping vá»›i patience tháº¥p hÆ¡n

### Training quÃ¡ cháº­m
- Báº­t mixed precision: `use_amp: true`
- TÄƒng batch_size (náº¿u GPU Ä‘á»§ RAM): `batch_size: 128`
- TÄƒng num_workers: `num_workers: 8`
- Kiá»ƒm tra GPU Ä‘Æ°á»£c sá»­ dá»¥ng: `nvidia-smi`

### Web demo khÃ´ng load
- Kiá»ƒm tra `webapp/frontend/index.html` tá»“n táº¡i
- Äáº£m báº£o port 8000 khÃ´ng bá»‹ chiáº¿m
- Xem log terminal Ä‘á»ƒ debug
- Thá»­ restart server: `Ctrl+C` rá»“i cháº¡y láº¡i `uvicorn`

### Lá»—i "Model architecture mismatch"
- Khi load checkpoint cÅ© vá»›i SmileNetV2 má»›i
- Giáº£i phÃ¡p: Train láº¡i tá»« Ä‘áº§u vá»›i kiáº¿n trÃºc má»›i
- Hoáº·c dÃ¹ng model cÅ©: `model: name: "SmileNet"`

---

## ğŸ“š Tham Kháº£o

- **YOLOv8**: [Ultralytics Documentation](https://docs.ultralytics.com/)
- **GENKI-4K**: Dataset cÃ´ng khai cho smile detection
- **PyTorch**: [pytorch.org](https://pytorch.org/)
- **FastAPI**: [fastapi.tiangolo.com](https://fastapi.tiangolo.com/)

